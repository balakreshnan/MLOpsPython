{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This template notebook assumes you have succcessfully ran through Challenge 2.  \n",
    "You should already have a train.py, driver_training.py, and a parameters.json in an experiment folder. These resources will be used as the first step in the Machine Learning pipeline created and run later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder for the experiment files used in Challenge 2\n",
    "training_folder = 'driver-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver-training/train_drivers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/train_drivers.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Dataset\n",
    "ws = Workspace.get(name='mlopsdev',\n",
    "           subscription_id='c46a9435-c957-4e6c-a0f4-b9a597984773',\n",
    "           resource_group='mlops'\n",
    ")\n",
    "\n",
    "#ws = Workspace.from_config()\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the safe driver prediction dataset\n",
    "#train_df = pd.read_csv('porto_seguro_safe_driver_prediction_input.csv')\n",
    "#train_df = run.input_datasets['driversdataset'].to_pandas_dataframe()\n",
    "dataset = Dataset.get_by_name(ws, name='driversdataset')\n",
    "data_df = dataset.to_pandas_dataframe()\n",
    "\n",
    "# Load the parameters for training the model from the file\n",
    "#with open(\"parameters.json\") as f:\n",
    "#    pars = json.load(f)\n",
    "#    parameters = pars[\"training\"]\n",
    "    \n",
    "parameters = {\n",
    "    'learning_rate': 0.02,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': 2\n",
    "}\n",
    "\n",
    "# Log each of the parameters to the run\n",
    "for param_name, param_value in parameters.items():\n",
    "    run.log(param_name, param_value)\n",
    "\n",
    "features = data_df.drop(['target', 'id'], axis=1)\n",
    "labels = np.array(data_df['target'])\n",
    "(features_train, features_valid, labels_train, labels_valid) = train_test_split(features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "train_data = lightgbm.Dataset(features_train, label=labels_train)\n",
    "valid_data = lightgbm.Dataset(features_valid, label=labels_valid, free_raw_data=False)\n",
    "    \n",
    "model = lightgbm.train(parameters, train_data, valid_sets=valid_data, num_boost_round=500, early_stopping_rounds=20)\n",
    "    \n",
    "#model = train_model(train_data, valid_data, parameters)\n",
    "#predictions = get_model_metrics(model, valid_data)\n",
    "\n",
    "predictions = model.predict(valid_data.data)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(valid_data.label, predictions)\n",
    "model_metrics = {\"auc\": (metrics.auc(fpr, tpr))}\n",
    "print(model_metrics)\n",
    "\n",
    "run.log('Accuracy', model_metrics)\n",
    "run.log('ModelType', 'LightGbm')\n",
    "\n",
    "# Save the trained model to the output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/driver_model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "print(output_path)\n",
    "print(model)\n",
    "\n",
    "# Save the trained model\n",
    "#os.makedirs(output_folder, exist_ok=True)\n",
    "#output_path = output_folder + \"/model.pkl\"\n",
    "#joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## register_model.py\n",
    "This script loads the model from where it was saved, and then registers it in the workspace. This will be the second step in the pipeline. The script is written to the experiment folder from this notebook for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver-training/register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/register_model.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"driver_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_name = 'driver_model'\n",
    "model_file = model_folder + \"/\" + model_name + \".pkl\"\n",
    "\n",
    "metrics=run.get_metrics(recursive=True)\n",
    "\n",
    "# Load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/driver_model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "#run.upload_file('driver_model.pkl',model_file)\n",
    "run.upload_file(model_name, model_file)\n",
    "\n",
    "#run.register_model(model_path = model_file,\n",
    "#                   model_name = 'driver_model.pkl', \n",
    "#                   tags=metrics)\n",
    "run.register_model(model_path = model_name,\n",
    "                   model_name = model_name, \n",
    "                   tags=metrics)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure Machine Learning Pipeline to Run the Scripts as a Pipeline\n",
    "\n",
    "See [this tutorial](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/05-Creating_a_Pipeline.ipynb) for a starting point\n",
    "\n",
    "Use the scikit-learn and lightgbm conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found compute target: cpu-cluster1\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "compute_name = \"cpu-cluster1\"\n",
    "vm_size = \"STANDARD_D14_V2\"\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found compute target: ' + compute_name)\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,  # STANDARD_NC6 is GPU-enabled\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=4)\n",
    "    # create the compute target\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current cluster status, use the 'status' property\n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "# Let Azure ML manage dependencies by setting user_managed_dependencies to False\n",
    "# Use docker containers by setting docker.enabled to True \n",
    "## TODO\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "drivers_env = Environment(\"drivers-pipeline-env\")\n",
    "drivers_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "drivers_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "drivers_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas', 'lightgbm'],\n",
    "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "drivers_env.python.conda_dependencies = drivers_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "drivers_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'drivers-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = compute_target\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'driver-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "#model_folder = \"models\"\n",
    "\n",
    "# Get the training dataset\n",
    "drivers_ds = ws.datasets.get(\"driversdataset\")\n",
    "\n",
    "# Create Step 1, which runs the estimator to train the model\n",
    "# Create an estimator\n",
    "#model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "#model_folder = \"models\"\n",
    "\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                        compute_target = compute_target,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train_drivers.py')\n",
    "\n",
    "\n",
    "# Create Step 2, which runs the model registration script\n",
    "## TODO\n",
    "# Step 1, run the estimator to train the model\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[drivers_ds.as_named_input('driversdataset')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = compute_target,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = training_folder,\n",
    "                                script_name = \"register_model.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = compute_target,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train Model [74ff141f][23bd3cb7-de8c-44a6-bf59-e94917378231], (This step will run and generate new outputs)\n",
      "Created step Register Model [a76527d9][7963a442-8156-44f6-bacc-4b6e0b644928], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun ec8f41a2-5f6c-4b76-bf59-23985951e381\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/ec8f41a2-5f6c-4b76-bf59-23985951e381?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b847c17cbb48ca856384ea5ceadb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/driver-training-pipeline/runs/ec8f41a2-5f6c-4b76-bf59-23985951e381?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\", \"run_id\": \"ec8f41a2-5f6c-4b76-bf59-23985951e381\", \"run_properties\": {\"run_id\": \"ec8f41a2-5f6c-4b76-bf59-23985951e381\", \"created_utc\": \"2021-01-24T17:06:41.725837Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-01-24T17:25:40.471615Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=UyMuP8M6mWEmakCQr8BeqMIgQ43yRPgYl1kBeRW%2F6so%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=n0EiayrsviDSH8gSR5W%2F6%2F3LfxJsSGoxSHv8PoWuS6g%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=K0aDrhW9f981DfZYO%2BcF%2BRgOVDtVVC86vS%2Bj%2BNreOOg%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:18:58\"}, \"child_runs\": [{\"run_id\": \"8608c8e0-c7ca-4451-b358-6b3cd38851f4\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:15:42.66329Z\", \"created_time\": \"2021-01-24T17:07:03.353917Z\", \"end_time\": \"2021-01-24T17:24:35.618569Z\", \"duration\": \"0:17:32\", \"run_number\": 57, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:07:03.353917Z\", \"is_reused\": \"\"}, {\"run_id\": \"39e81cf3-9b2a-4557-b7ed-db126976188a\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:24:54.516644Z\", \"created_time\": \"2021-01-24T17:24:41.134651Z\", \"end_time\": \"2021-01-24T17:25:25.456891Z\", \"duration\": \"0:00:44\", \"run_number\": 58, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:24:41.134651Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-24 17:07:03Z] Submitting 1 runs, first five are: 74ff141f:8608c8e0-c7ca-4451-b358-6b3cd38851f4\\n[2021-01-24 17:24:40Z] Completing processing run id 8608c8e0-c7ca-4451-b358-6b3cd38851f4.\\n[2021-01-24 17:24:40Z] Submitting 1 runs, first five are: a76527d9:39e81cf3-9b2a-4557-b7ed-db126976188a\\n[2021-01-24 17:25:40Z] Completing processing run id 39e81cf3-9b2a-4557-b7ed-db126976188a.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"ebe2e643\": {\"node_id\": \"ebe2e643\", \"name\": \"driversdataset\"}}, \"module_nodes\": {\"74ff141f\": {\"node_id\": \"74ff141f\", \"name\": \"Train Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"8608c8e0-c7ca-4451-b358-6b3cd38851f4\"}, \"a76527d9\": {\"node_id\": \"a76527d9\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"39e81cf3-9b2a-4557-b7ed-db126976188a\"}}, \"edges\": [{\"source_node_id\": \"ebe2e643\", \"source_node_name\": \"driversdataset\", \"source_name\": \"data\", \"target_name\": \"driversdataset\", \"dst_node_id\": \"74ff141f\", \"dst_node_name\": \"Train Model\"}, {\"source_node_id\": \"74ff141f\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"a76527d9\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"8608c8e0-c7ca-4451-b358-6b3cd38851f4\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:15:42.66329Z\", \"created_time\": \"2021-01-24T17:07:03.353917Z\", \"end_time\": \"2021-01-24T17:24:35.618569Z\", \"duration\": \"0:17:32\", \"run_number\": 57, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:07:03.353917Z\", \"is_reused\": \"\"}, {\"run_id\": \"39e81cf3-9b2a-4557-b7ed-db126976188a\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:24:54.516644Z\", \"created_time\": \"2021-01-24T17:24:41.134651Z\", \"end_time\": \"2021-01-24T17:25:25.456891Z\", \"duration\": \"0:00:44\", \"run_number\": 58, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:24:41.134651Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: ec8f41a2-5f6c-4b76-bf59-23985951e381\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/ec8f41a2-5f6c-4b76-bf59-23985951e381?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 8608c8e0-c7ca-4451-b358-6b3cd38851f4\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/8608c8e0-c7ca-4451-b358-6b3cd38851f4?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/01/24 17:07:15 Downloading source code...\n",
      "2021/01/24 17:07:16 Finished downloading source code\n",
      "2021/01/24 17:07:17 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/01/24 17:07:17 Successfully set up Docker network: acb_default_network\n",
      "2021/01/24 17:07:17 Setting up Docker configuration...\n",
      "2021/01/24 17:07:18 Successfully set up Docker configuration\n",
      "2021/01/24 17:07:18 Logging in to registry: mlopsdev82752047.azurecr.io\n",
      "2021/01/24 17:07:19 Successfully logged into mlopsdev82752047.azurecr.io\n",
      "2021/01/24 17:07:19 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/01/24 17:07:19 Scanning for dependencies...\n",
      "2021/01/24 17:07:20 Successfully scanned dependencies\n",
      "2021/01/24 17:07:20 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  64.51kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "73eef93b7466: Waiting\n",
      "d5a54c1fb97f: Waiting\n",
      "1536f6ca931b: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "86b4bf2f8d5f: Waiting\n",
      "5335952fa8d3: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "a613a9b4553c: Verifying Checksum\n",
      "a613a9b4553c: Download complete\n",
      "acc000f01536: Verifying Checksum\n",
      "acc000f01536: Download complete\n",
      "73eef93b7466: Verifying Checksum\n",
      "73eef93b7466: Download complete\n",
      "8e097b52bfb8: Verifying Checksum\n",
      "8e097b52bfb8: Download complete\n",
      "1536f6ca931b: Verifying Checksum\n",
      "1536f6ca931b: Download complete\n",
      "d7b631d130cb: Verifying Checksum\n",
      "d7b631d130cb: Download complete\n",
      "d5a54c1fb97f: Verifying Checksum\n",
      "d5a54c1fb97f: Download complete\n",
      "75ffe8dfb222: Verifying Checksum\n",
      "75ffe8dfb222: Download complete\n",
      "5335952fa8d3: Verifying Checksum\n",
      "5335952fa8d3: Download complete\n",
      "96fa3cc6fe10: Verifying Checksum\n",
      "96fa3cc6fe10: Download complete\n",
      "e428dd9daa94: Verifying Checksum\n",
      "e428dd9daa94: Download complete\n",
      "86b4bf2f8d5f: Verifying Checksum\n",
      "86b4bf2f8d5f: Download complete\n",
      "8e097b52bfb8: Pull complete\n",
      "a613a9b4553c: Pull complete\n",
      "acc000f01536: Pull complete\n",
      "73eef93b7466: Pull complete\n",
      "d5a54c1fb97f: Pull complete\n",
      "1536f6ca931b: Pull complete\n",
      "d7b631d130cb: Pull complete\n",
      "75ffe8dfb222: Pull complete\n",
      "86b4bf2f8d5f: Pull complete\n",
      "5335952fa8d3: Pull complete\n",
      "96fa3cc6fe10: Pull complete\n",
      "e428dd9daa94: Pull complete\n",
      "Digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      " ---> 287916b809d9\n",
      "Step 2/15 : USER root\n",
      " ---> Running in 209a5b859022\n",
      "Removing intermediate container 209a5b859022\n",
      " ---> 85a7212cb821\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 7bb1b42f3a8a\n",
      "Removing intermediate container 7bb1b42f3a8a\n",
      " ---> d90864a2317a\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 3c63c3188cfd\n",
      "Removing intermediate container 3c63c3188cfd\n",
      " ---> e84ff9ec585c\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 9e9893123934\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 9d9a0b10fb07\n",
      "Removing intermediate container 9d9a0b10fb07\n",
      " ---> 7d658a6e2ebd\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 413c49a98fca\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 36dc8a27d732\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ###        |  31% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "joblib-0.17.0        | 205 KB    |            |   0% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "\n",
      "pytz-2020.1          | 239 KB    |            |   0% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "\n",
      "numpy-1.19.1         | 20 KB     |            |   0% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | 5          |   5% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "\n",
      "lightgbm-2.3.0       | 1.0 MB    |            |   0% \n",
      "lightgbm-2.3.0       | 1.0 MB    | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
      "scipy-1.5.2          | 18.5 MB   | ###        |  30% \n",
      "scipy-1.5.2          | 18.5 MB   | ########7  |  88% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ###6       |  36% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | #######8   |  79% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "pandas-1.1.3         | 10.5 MB   |            |   0% \n",
      "pandas-1.1.3         | 10.5 MB   |            |   0% \n",
      "pandas-1.1.3         | 10.5 MB   | ###9       |  40% \n",
      "pandas-1.1.3         | 10.5 MB   | ######5    |  65% \n",
      "pandas-1.1.3         | 10.5 MB   | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | 6          |   6% \n",
      "python-3.6.2         | 27.0 MB   | ##9        |  30% \n",
      "python-3.6.2         | 27.0 MB   | ####3      |  43% \n",
      "python-3.6.2         | 27.0 MB   | #####3     |  53% \n",
      "python-3.6.2         | 27.0 MB   | ######2    |  63% \n",
      "python-3.6.2         | 27.0 MB   | #######2   |  73% \n",
      "python-3.6.2         | 27.0 MB   | ########1  |  82% \n",
      "python-3.6.2         | 27.0 MB   | #########1 |  91% \n",
      "python-3.6.2         | 27.0 MB   | #########9 |  99% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | 8          |   9% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  | 3          |   4% \n",
      "mkl-2019.4           | 204.1 MB  | 7          |   8% \n",
      "mkl-2019.4           | 204.1 MB  | #3         |  14% \n",
      "mkl-2019.4           | 204.1 MB  | #8         |  18% \n",
      "mkl-2019.4           | 204.1 MB  | ##3        |  23% \n",
      "mkl-2019.4           | 204.1 MB  | ##8        |  28% \n",
      "mkl-2019.4           | 204.1 MB  | ###4       |  35% \n",
      "mkl-2019.4           | 204.1 MB  | ####       |  40% \n",
      "mkl-2019.4           | 204.1 MB  | ####5      |  46% \n",
      "mkl-2019.4           | 204.1 MB  | #####      |  51% \n",
      "mkl-2019.4           | 204.1 MB  | #####6     |  56% \n",
      "mkl-2019.4           | 204.1 MB  | ######1    |  62% \n",
      "mkl-2019.4           | 204.1 MB  | ######7    |  67% \n",
      "mkl-2019.4           | 204.1 MB  | #######2   |  73% \n",
      "mkl-2019.4           | 204.1 MB  | #######6   |  77% \n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  81% \n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #####4     |  55% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "six-1.15.0           | 13 KB     |            |   0% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.rlt03bih.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults~=1.19.0\n",
      "  Downloading azureml_defaults-1.19.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting azureml-dataprep[pandas]\n",
      "  Downloading azureml_dataprep-2.9.0-py3-none-any.whl (39.4 MB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.19.0\n",
      "  Downloading azureml_dataset_runtime-1.19.0.post1-py3-none-any.whl (3.5 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting azureml-core~=1.19.0\n",
      "  Downloading azureml_core-1.19.0-py3-none-any.whl (2.1 MB)\n",
      "Collecting azureml-dataprep-rslex<1.8.0a,>=1.7.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.7.0-cp36-cp36m-manylinux2010_x86_64.whl (8.5 MB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting azureml-dataprep-native<30.0.0,>=29.0.0\n",
      "  Downloading azureml_dataprep_native-29.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.rlt03bih.requirements.txt (line 2)) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas<2.0.0,>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.rlt03bih.requirements.txt (line 2)) (1.1.3)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0; extra == \"pandas\"\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.19.0->-r /azureml-environment-setup/condaenv.rlt03bih.requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.19.0->-r /azureml-environment-setup/condaenv.rlt03bih.requirements.txt (line 1)) (2020.1)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.19.0->-r /azureml-environment-setup/condaenv.rlt03bih.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.6-py2.py3-none-any.whl (55 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.5.0-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting PyJWT<2.0.0\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.26-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-12.0.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.4.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting pyopenssl<20.0.0\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.8.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.10.0-py2.py3-none-any.whl (125 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.19.0->-r /azureml-environment-setup/condaenv.rlt03bih.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-3.4.0-py3-none-any.whl (10 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.4-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=f306b04d8eac27ec915b408826de64d8ee8838ebf65477b7b7d0eb7671b65f49\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=8b645bc0c17207c8ec60f5ebdd52fe89680aa059316eadf88a070269b6c2bd52\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=5b89d14e9f99aa6e271fa8bf5a380889a3ca822e714b00352f09809679c56825\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built json-logging-py fusepy liac-arff\n",
      "Installing collected packages: pyarrow, azureml-dataprep-rslex, portalocker, PyJWT, pycparser, cffi, cryptography, chardet, urllib3, idna, requests, msal, msal-extensions, azure-core, azure-identity, cloudpickle, azureml-dataprep-native, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, gunicorn, applicationinsights, dill, liac-arff, adal, azureml-model-management-sdk, configparser, werkzeug, json-logging-py, MarkupSafe, Jinja2, itsdangerous, click, flask, azure-common, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-mgmt-storage, typing-extensions, zipp, importlib-metadata, jsonpickle, azure-mgmt-authorization, jeepney, SecretStorage, azure-mgmt-keyvault, ruamel.yaml.clib, ruamel.yaml, jmespath, backports.weakref, backports.tempfile, azure-graphrbac, pathspec, azure-mgmt-resource, websocket-client, docker, contextlib2, pyasn1, pyopenssl, ndg-httpsclient, azure-mgmt-containerregistry, azureml-core, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.3.0 adal-1.2.6 applicationinsights-0.11.9 azure-common-1.1.26 azure-core-1.10.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.19.0 azureml-dataprep-2.9.0 azureml-dataprep-native-29.0.0 azureml-dataprep-rslex-1.7.0 azureml-dataset-runtime-1.19.0.post1 azureml-defaults-1.19.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.4 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.3.1 dill-0.3.3 distro-1.5.0 docker-4.4.1 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-3.4.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-1.5.0 liac-arff-2.5.0 msal-1.8.0 msal-extensions-0.2.2 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pathspec-0.8.1 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 typing-extensions-3.7.4.3 urllib3-1.26.2 websocket-client-0.57.0 werkzeug-1.0.1 zipp-3.4.0\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 36dc8a27d732\n",
      " ---> 2154f90f9c32\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin:$PATH\n",
      " ---> Running in fe42fa7f73ed\n",
      "Removing intermediate container fe42fa7f73ed\n",
      " ---> 804cef218d40\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf\n",
      " ---> Running in 9813dc7d5d66\n",
      "Removing intermediate container 9813dc7d5d66\n",
      " ---> 2d92ac9edf3c\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 047b539f0b69\n",
      "Removing intermediate container 047b539f0b69\n",
      " ---> a3ba35492070\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> cdb1f3c21eb7\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 4447d9af9fa2\n",
      "Removing intermediate container 4447d9af9fa2\n",
      " ---> b52f30adac84\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 726f66931938\n",
      "Removing intermediate container 726f66931938\n",
      " ---> c06e4e2a85d3\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in 5d77d75cdb39\n",
      "Removing intermediate container 5d77d75cdb39\n",
      " ---> 67db1742e74b\n",
      "Successfully built 67db1742e74b\n",
      "Successfully tagged mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest\n",
      "2021/01/24 17:10:37 Successfully executed container: acb_step_0\n",
      "2021/01/24 17:10:37 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/01/24 17:10:37 Pushing image: mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest, attempt 1\n",
      "The push refers to repository [mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e]\n",
      "f320f416f4ad: Preparing\n",
      "b7c651d408a4: Preparing\n",
      "bb5fcd0fc329: Preparing\n",
      "63a43d266ef7: Preparing\n",
      "81fb24b1573b: Preparing\n",
      "8b064c4cfe32: Preparing\n",
      "13e378616f24: Preparing\n",
      "efc99d952c3d: Preparing\n",
      "9e292a80b88a: Preparing\n",
      "5e1805eb9eb5: Preparing\n",
      "8dab94e6d05c: Preparing\n",
      "2817caf0a082: Preparing\n",
      "aece08fd27fc: Preparing\n",
      "4caea5ef1f0b: Preparing\n",
      "dcc0cc99372e: Preparing\n",
      "87c128261339: Preparing\n",
      "41a253a417e6: Preparing\n",
      "e06660e80cf4: Preparing\n",
      "8b064c4cfe32: Waiting\n",
      "13e378616f24: Waiting\n",
      "efc99d952c3d: Waiting\n",
      "9e292a80b88a: Waiting\n",
      "5e1805eb9eb5: Waiting\n",
      "8dab94e6d05c: Waiting\n",
      "2817caf0a082: Waiting\n",
      "aece08fd27fc: Waiting\n",
      "4caea5ef1f0b: Waiting\n",
      "dcc0cc99372e: Waiting\n",
      "87c128261339: Waiting\n",
      "41a253a417e6: Waiting\n",
      "e06660e80cf4: Waiting\n",
      "63a43d266ef7: Pushed\n",
      "f320f416f4ad: Pushed\n",
      "81fb24b1573b: Pushed\n",
      "bb5fcd0fc329: Pushed\n",
      "8b064c4cfe32: Pushed\n",
      "efc99d952c3d: Pushed\n",
      "13e378616f24: Pushed\n",
      "9e292a80b88a: Pushed\n",
      "aece08fd27fc: Pushed\n",
      "2817caf0a082: Pushed\n",
      "dcc0cc99372e: Pushed\n",
      "5e1805eb9eb5: Pushed\n",
      "8dab94e6d05c: Pushed\n",
      "87c128261339: Pushed\n",
      "41a253a417e6: Pushed\n",
      "4caea5ef1f0b: Pushed\n",
      "e06660e80cf4: Pushed\n",
      "b7c651d408a4: Pushed\n",
      "latest: digest: sha256:5725a4c975a182db05ccd3b876974ef0bf64345fe498d4c404ad85c8cf9f0f69 size: 4095\n",
      "2021/01/24 17:12:40 Successfully pushed image: mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest\n",
      "2021/01/24 17:12:40 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 198.494621)\n",
      "2021/01/24 17:12:40 Populating digests for step ID: acb_step_0...\n",
      "2021/01/24 17:12:42 Successfully populated digests for step ID: acb_step_0\n",
      "2021/01/24 17:12:42 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 122.938125)\n",
      "2021/01/24 17:12:42 The following dependencies were found:\n",
      "2021/01/24 17:12:42 \n",
      "- image:\n",
      "    registry: mlopsdev82752047.azurecr.io\n",
      "    repository: azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      "    tag: latest\n",
      "    digest: sha256:5725a4c975a182db05ccd3b876974ef0bf64345fe498d4c404ad85c8cf9f0f69\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20200821.v1\n",
      "    digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cjy was successful after 5m28s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      "========================================================================================================================\n",
      "2021-01-24T17:15:56Z Starting output-watcher...\n",
      "2021-01-24T17:15:56Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-01-24T17:15:58Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-01-24T17:15:58Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "b7e5872278b8: Pulling fs layer\n",
      "8a6db6255dba: Pulling fs layer\n",
      "199a565c14a3: Pulling fs layer\n",
      "c864622cfe6a: Pulling fs layer\n",
      "5c40c66f8473: Pulling fs layer\n",
      "676e7bcd7910: Pulling fs layer\n",
      "86b4bf2f8d5f: Waiting\n",
      "5335952fa8d3: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "b7e5872278b8: Waiting\n",
      "8a6db6255dba: Waiting\n",
      "199a565c14a3: Waiting\n",
      "c864622cfe6a: Waiting\n",
      "5c40c66f8473: Waiting\n",
      "676e7bcd7910: Waiting\n",
      "73eef93b7466: Waiting\n",
      "d5a54c1fb97f: Waiting\n",
      "1536f6ca931b: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "a613a9b4553c: Verifying Checksum\n",
      "a613a9b4553c: Download complete\n",
      "acc000f01536: Verifying Checksum\n",
      "73eef93b7466: Verifying Checksum\n",
      "73eef93b7466: Download complete\n",
      "8e097b52bfb8: Verifying Checksum\n",
      "8e097b52bfb8: Download complete\n",
      "d7b631d130cb: Verifying Checksum\n",
      "d7b631d130cb: Download complete\n",
      "1536f6ca931b: Verifying Checksum\n",
      "1536f6ca931b: Download complete\n",
      "d5a54c1fb97f: Verifying Checksum\n",
      "d5a54c1fb97f: Download complete\n",
      "8e097b52bfb8: Pull complete\n",
      "a613a9b4553c: Pull complete\n",
      "acc000f01536: Pull complete\n",
      "73eef93b7466: Pull complete\n",
      "75ffe8dfb222: Verifying Checksum\n",
      "75ffe8dfb222: Download complete\n",
      "5335952fa8d3: Verifying Checksum\n",
      "5335952fa8d3: Download complete\n",
      "96fa3cc6fe10: Verifying Checksum\n",
      "96fa3cc6fe10: Download complete\n",
      "86b4bf2f8d5f: Verifying Checksum\n",
      "86b4bf2f8d5f: Download complete\n",
      "8a6db6255dba: Verifying Checksum\n",
      "8a6db6255dba: Download complete\n",
      "b7e5872278b8: Verifying Checksum\n",
      "b7e5872278b8: Download complete\n",
      "e428dd9daa94: Verifying Checksum\n",
      "e428dd9daa94: Download complete\n",
      "c864622cfe6a: Verifying Checksum\n",
      "c864622cfe6a: Download complete\n",
      "676e7bcd7910: Verifying Checksum\n",
      "676e7bcd7910: Download complete\n",
      "199a565c14a3: Verifying Checksum\n",
      "199a565c14a3: Download complete\n",
      "d5a54c1fb97f: Pull complete\n",
      "1536f6ca931b: Pull complete\n",
      "d7b631d130cb: Pull complete\n",
      "5c40c66f8473: Verifying Checksum\n",
      "5c40c66f8473: Download complete\n",
      "75ffe8dfb222: Pull complete\n",
      "86b4bf2f8d5f: Pull complete\n",
      "5335952fa8d3: Pull complete\n",
      "96fa3cc6fe10: Pull complete\n",
      "e428dd9daa94: Pull complete\n",
      "b7e5872278b8: Pull complete\n",
      "8a6db6255dba: Pull complete\n",
      "199a565c14a3: Pull complete\n",
      "c864622cfe6a: Pull complete\n",
      "5c40c66f8473: Pull complete\n",
      "676e7bcd7910: Pull complete\n",
      "Digest: sha256:5725a4c975a182db05ccd3b876974ef0bf64345fe498d4c404ad85c8cf9f0f69\n",
      "Status: Downloaded newer image for mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest\n",
      "mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest\n",
      "2021-01-24T17:16:24Z Check if container 8608c8e0-c7ca-4451-b358-6b3cd38851f4 already exist exited with 0, \n",
      "\n",
      "607d3c65e88526f4069ce9aed74a230bfaa1858eb3aefa8aef6b08c615f1fb21\n",
      "2021/01/24 17:16:33 Starting App Insight Logger for task:  containerSetup\n",
      "2021/01/24 17:16:33 Version: 3.0.01467.0023 Branch: .SourceBranch Commit: 8f9022f\n",
      "2021/01/24 17:16:33 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/01/24 17:16:33 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/01/24 17:16:33 sshd inside container not required for job, skipping setup.\n",
      "2021/01/24 17:16:33 All App Insights Logs was send successfully\n",
      "2021-01-24T17:16:34Z Starting docker container succeeded.\n",
      "2021-01-24T17:16:42Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/01/24 17:15:50 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/01/24 17:15:50 Version: 3.0.01467.0023 Branch: .SourceBranch Commit: 8f9022f\n",
      ">>>   2021/01/24 17:15:50 runtime.GOOS linux\n",
      ">>>   2021/01/24 17:15:50 Reading dyanamic configs\n",
      ">>>   2021/01/24 17:15:50 Container sas url: https://baiscriptsdm1prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=jERbQtYUS5wH4oi8gxo4Rfe9yxPy25mLk7UYJIRzAsA%3D\n",
      ">>>   2021/01/24 17:15:50 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: not a directory\n",
      ">>>   2021/01/24 17:15:50 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed true, isEnable true,\n",
      ">>>   2021/01/24 17:15:50 azsecpack isEnable:true,GetDisableVsatlsscan:true\n",
      ">>>   2021/01/24 17:15:50 start to install azsecpack..., MachineName is 8123289e505549148fc0913dc8378106000000 \n",
      ">>>   \n",
      ">>>   2021/01/24 17:15:53 \n",
      ">>>   2021/01/24 17:15:53 \n",
      ">>>   2021/01/24 17:15:53 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/01/24 17:15:53 DetonationChamber is not enabled on this subscription: c46a9435-c957-4e6c-a0f4-b9a597984773\n",
      ">>>   2021/01/24 17:15:53 GPU count found: 0\n",
      ">>>   2021/01/24 17:15:53 AMLComputeXDSEndpoint:  https://dm1-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/01/24 17:15:53 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/01/24 17:15:53 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config\n",
      ">>>   2021/01/24 17:15:53 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/01/24 17:15:53 Starting identity responder.\n",
      ">>>   2021/01/24 17:15:53 Starting identity responder.\n",
      ">>>   2021/01/24 17:15:53 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2021/01/24 17:15:53 Logfile used for identity responder: /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/IdentityResponderLog-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:15:53 Logfile used for identity responder: /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/IdentityResponderLog-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:15:53 Started Identity Responder for job.\n",
      ">>>   2021/01/24 17:15:53 Started Identity Responder for job.\n",
      ">>>   2021/01/24 17:15:53 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/wd\n",
      ">>>   2021/01/24 17:15:53 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/shared\n",
      ">>>   2021/01/24 17:15:53 Mounting job level file systems\n",
      ">>>   2021/01/24 17:15:53 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts\n",
      ">>>   2021/01/24 17:15:53 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/01/24 17:15:53 Datastore credentials file not found, skipping.\n",
      ">>>   2021/01/24 17:15:53 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.master.runtimesastokens\n",
      ">>>   2021/01/24 17:15:53 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/01/24 17:15:53 No NFS configured\n",
      ">>>   2021/01/24 17:15:53 No Azure File Shares configured\n",
      ">>>   2021/01/24 17:15:53 Mounting blob file systems\n",
      ">>>   2021/01/24 17:15:53 Blobfuse runtime version blobfuse 1.3.6\n",
      ">>>   2021/01/24 17:15:53 Mounting azureml-blobstore-0fb30f4c-f96f-4ccb-98e8-b741ce9e8f19 container from mlopsdev3695286978 account at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:15:53 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/01/24 17:15:53 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/01/24 17:15:53 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/01/24 17:15:53 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:15:53 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:15:54 Successfully mounted azureml-blobstore-0fb30f4c-f96f-4ccb-98e8-b741ce9e8f19 container from mlopsdev3695286978 account at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:15:54 No unmanaged file systems configured\n",
      ">>>   2021/01/24 17:15:54 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/01/24 17:15:54 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs\n",
      ">>>   2021/01/24 17:15:55 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs\n",
      ">>>   2021/01/24 17:15:55 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/outputs\n",
      ">>>   2021/01/24 17:15:56 Starting output-watcher...\n",
      ">>>   2021/01/24 17:15:56 Single file input dataset is enabled.\n",
      ">>>   2021/01/24 17:15:56 Start to pulling docker image: mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      ">>>   2021/01/24 17:15:56 Start pull docker image: mlopsdev82752047.azurecr.io\n",
      ">>>   2021/01/24 17:15:56 Container registry is ACR.\n",
      ">>>   2021/01/24 17:15:56 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/01/24 17:15:56 Getting ACR Credentials from EMS for environment drivers-pipeline-env:4\n",
      ">>>   2021/01/24 17:15:56 Requesting XDS for registry details.\n",
      ">>>   2021/01/24 17:15:56 Attempt 1 of http call to https://dm1-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourceGroups/mlops/workspaces/mlopsdev/clusters/cpu-cluster1/nodes/tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d?api-version=2018-02-01\n",
      ">>>   2021/01/24 17:15:58 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2021/01/24 17:15:58 Got container registry details from credentials service for registry address: mlopsdev82752047.azurecr.io.\n",
      ">>>   2021/01/24 17:15:58 Writing ACR Details to file...\n",
      ">>>   2021/01/24 17:15:58 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/01/24 17:15:58 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/01/24 17:15:58 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/01/24 17:15:58 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/01/24 17:15:58 EMS returned mlopsdev82752047.azurecr.io for environment drivers-pipeline-env\n",
      ">>>   2021/01/24 17:15:58 start login to the docker registry\n",
      ">>>   2021/01/24 17:15:59 Successfully logged into the docker registry.\n",
      ">>>   2021/01/24 17:15:59 Start run pull docker image command\n",
      ">>>   2021/01/24 17:16:24 Pull docker image succeeded.\n",
      ">>>   2021/01/24 17:16:24 Pull docker image time: 28.145786359s\n",
      ">>>   \n",
      ">>>   2021/01/24 17:16:24 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/01/24 17:16:24 Setting the memory limit for docker container to be 112457 MB\n",
      ">>>   2021/01/24 17:16:24 The env variable file size is 37150 bytes\n",
      ">>>   2021/01/24 17:16:24 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,8608c8e0-c7ca-4451-b358-6b3cd38851f4,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/certs:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,112457m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd,-v,/opt/azureml:/opt/azureml:ro,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.batchai.envlist\n",
      ">>>   2021/01/24 17:16:24 the binding /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4 \n",
      ">>>   2021/01/24 17:16:24 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,8608c8e0-c7ca-4451-b358-6b3cd38851f4,-m,112457m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.batchai.envlist,-v,/opt/azureml:/opt/azureml:ro,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/certs:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/certs\n",
      ">>>   2021/01/24 17:16:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/01/24 17:16:24 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 8608c8e0-c7ca-4451-b358-6b3cd38851f4 -m 112457m -w /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/config/.batchai.envlist -v /opt/azureml:/opt/azureml:ro -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4 -v /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd -v /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/certs:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/certs --shm-size 2g -d -it --privileged --net=host mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      ">>>   2021/01/24 17:16:24 Check if container 8608c8e0-c7ca-4451-b358-6b3cd38851f4 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/01/24 17:16:24 Check if container 8608c8e0-c7ca-4451-b358-6b3cd38851f4 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/01/24 17:16:25 Attempt 1 of http call to https://centralus.experiments.azureml.net/history/v1.0/private/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourceGroups/mlops/providers/Microsoft.MachineLearningServices/workspaces/mlopsdev/runs/8608c8e0-c7ca-4451-b358-6b3cd38851f4/spans\n",
      ">>>   2021/01/24 17:16:34 Container ssh is not required for job type.\n",
      ">>>   2021/01/24 17:16:34 Starting docker container succeeded.\n",
      ">>>   2021/01/24 17:16:34 Starting docker container succeeded.\n",
      ">>>   2021/01/24 17:16:34 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs\n",
      ">>>   2021/01/24 17:16:34 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"abf0ed80-fa52-44ea-bd06-398759dc7497\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/01/24 17:16:34 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:16:34 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml_compute_logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:16:34 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4;/azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"abf0ed80-fa52-44ea-bd06-398759dc7497\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/01/24 17:16:34 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/01/24 17:16:34 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t 8608c8e0-c7ca-4451-b358-6b3cd38851f4 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/8608c8e0-c7ca-4451-b_6546acb4-9009-42e9-b6bc-ae4911621b5e/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4;/azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"abf0ed80-fa52-44ea-bd06-398759dc7497\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:34.527103] Entering job preparation.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:35.829280] Starting job preparation.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:35.829336] Extracting the control code.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:35.848705] fetching and extracting the control code on master node.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:35.848749] Starting extract_project.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:35.848797] Starting to extract zip file.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:36.679498] Finished extracting zip file.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:36.858097] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:36.858187] Start fetching snapshots.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:36.858234] Start fetching snapshot.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:36.858262] Retrieving project from snapshot: abf0ed80-fa52-44ea-bd06-398759dc7497\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 55\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.669986] Finished fetching snapshot.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.670033] Finished fetching snapshots.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.670043] Finished extract_project.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.681624] Finished fetching and extracting the control code.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.685844] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.687785] Start run_history_prep.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:40.742508] Entering context manager injector.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: Acquired lockfile /tmp/8608c8e0-c7ca-4451-b358-6b3cd38851f4-datastore.lock to downloading input data references\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:41.405427] downloadDataStore completed\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:41.410778] Job preparation is complete.\n",
      ">>>   2021/01/24 17:16:41 runSpecialJobTask: preparation: [2021-01-24T17:16:41.410846] Running Context Managers in Sidecar complete.\n",
      ">>>   2021/01/24 17:16:42 All App Insights Logs was send successfully\n",
      ">>>   2021/01/24 17:16:42 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2021-01-24T17:16:42Z 127.0.0.1 slots=16 max-slots=16\n",
      "2021-01-24T17:16:42Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/01/24 17:16:42 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
      "2021/01/24 17:16:42 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
      "[2021-01-24T17:16:44.078010] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['train_drivers.py', '--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/model_folder'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 109\n",
      "Entering Run History Context Manager.\n",
      "[2021-01-24T17:16:46.804457] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4\n",
      "[2021-01-24T17:16:46.804646] Preparing to call script [train_drivers.py] with arguments:['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/model_folder']\n",
      "[2021-01-24T17:16:46.804726] After variable expansion, calling script [train_drivers.py] with arguments:['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/model_folder']\n",
      "\n",
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code RRCFLAWGR to authenticate.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n",
      "[LightGBM] [Info] Total Bins 1371\n",
      "[LightGBM] [Info] Number of data: 476169, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n",
      "[LightGBM] [Info] Start training from score -3.273091\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[1]\tvalid_0's auc: 0.595844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[2]\tvalid_0's auc: 0.605252\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[3]\tvalid_0's auc: 0.612784\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[4]\tvalid_0's auc: 0.61756\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[5]\tvalid_0's auc: 0.620129\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[6]\tvalid_0's auc: 0.622447\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[7]\tvalid_0's auc: 0.622163\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[8]\tvalid_0's auc: 0.622112\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[9]\tvalid_0's auc: 0.622581\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[10]\tvalid_0's auc: 0.622278\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[11]\tvalid_0's auc: 0.622433\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[12]\tvalid_0's auc: 0.623423\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[13]\tvalid_0's auc: 0.623618\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 8\n",
      "[14]\tvalid_0's auc: 0.62414\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[15]\tvalid_0's auc: 0.624421\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[16]\tvalid_0's auc: 0.624512\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[17]\tvalid_0's auc: 0.625151\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[18]\tvalid_0's auc: 0.62529\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[19]\tvalid_0's auc: 0.625437\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[20]\tvalid_0's auc: 0.62563\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[21]\tvalid_0's auc: 0.625963\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[22]\tvalid_0's auc: 0.626147\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[23]\tvalid_0's auc: 0.626383\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[24]\tvalid_0's auc: 0.626618\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 8\n",
      "[25]\tvalid_0's auc: 0.626586\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[26]\tvalid_0's auc: 0.626839\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[27]\tvalid_0's auc: 0.626972\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[28]\tvalid_0's auc: 0.626935\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[29]\tvalid_0's auc: 0.626946\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[30]\tvalid_0's auc: 0.627204\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[31]\tvalid_0's auc: 0.627252\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[32]\tvalid_0's auc: 0.627302\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[33]\tvalid_0's auc: 0.627249\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[34]\tvalid_0's auc: 0.627517\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[35]\tvalid_0's auc: 0.627755\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 8\n",
      "[36]\tvalid_0's auc: 0.62766\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[37]\tvalid_0's auc: 0.627483\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[38]\tvalid_0's auc: 0.627578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[39]\tvalid_0's auc: 0.627433\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[40]\tvalid_0's auc: 0.627573\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[41]\tvalid_0's auc: 0.627908\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[42]\tvalid_0's auc: 0.627968\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[43]\tvalid_0's auc: 0.628082\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[44]\tvalid_0's auc: 0.628398\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[45]\tvalid_0's auc: 0.628763\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[46]\tvalid_0's auc: 0.629011\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[47]\tvalid_0's auc: 0.629321\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[48]\tvalid_0's auc: 0.629341\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[49]\tvalid_0's auc: 0.629353\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[50]\tvalid_0's auc: 0.629291\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[51]\tvalid_0's auc: 0.629447\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[52]\tvalid_0's auc: 0.629507\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[53]\tvalid_0's auc: 0.629725\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[54]\tvalid_0's auc: 0.630048\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[55]\tvalid_0's auc: 0.630085\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[56]\tvalid_0's auc: 0.630035\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[57]\tvalid_0's auc: 0.630236\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[58]\tvalid_0's auc: 0.630486\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[59]\tvalid_0's auc: 0.630663\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[60]\tvalid_0's auc: 0.630787\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[61]\tvalid_0's auc: 0.630932\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[62]\tvalid_0's auc: 0.631004\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[63]\tvalid_0's auc: 0.631161\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[64]\tvalid_0's auc: 0.631407\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[65]\tvalid_0's auc: 0.631408\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 9\n",
      "[66]\tvalid_0's auc: 0.631515\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[67]\tvalid_0's auc: 0.631631\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[68]\tvalid_0's auc: 0.631628\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[69]\tvalid_0's auc: 0.631703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[70]\tvalid_0's auc: 0.631781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[71]\tvalid_0's auc: 0.631786\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[72]\tvalid_0's auc: 0.631779\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[73]\tvalid_0's auc: 0.632022\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[74]\tvalid_0's auc: 0.632086\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[75]\tvalid_0's auc: 0.632107\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[76]\tvalid_0's auc: 0.632201\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[77]\tvalid_0's auc: 0.632165\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[78]\tvalid_0's auc: 0.632335\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[79]\tvalid_0's auc: 0.632446\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[80]\tvalid_0's auc: 0.63254\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[81]\tvalid_0's auc: 0.632654\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[82]\tvalid_0's auc: 0.632663\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[83]\tvalid_0's auc: 0.632811\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[84]\tvalid_0's auc: 0.63291\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[85]\tvalid_0's auc: 0.632993\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[86]\tvalid_0's auc: 0.632962\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[87]\tvalid_0's auc: 0.632941\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[88]\tvalid_0's auc: 0.633062\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[89]\tvalid_0's auc: 0.633144\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[90]\tvalid_0's auc: 0.633242\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[91]\tvalid_0's auc: 0.633336\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[92]\tvalid_0's auc: 0.633453\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[93]\tvalid_0's auc: 0.633556\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[94]\tvalid_0's auc: 0.633648\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[95]\tvalid_0's auc: 0.633762\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[96]\tvalid_0's auc: 0.633831\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[97]\tvalid_0's auc: 0.633922\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[98]\tvalid_0's auc: 0.633908\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[99]\tvalid_0's auc: 0.633958\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[100]\tvalid_0's auc: 0.634122\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[101]\tvalid_0's auc: 0.634278\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[102]\tvalid_0's auc: 0.634301\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[103]\tvalid_0's auc: 0.634313\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[104]\tvalid_0's auc: 0.634366\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[105]\tvalid_0's auc: 0.634497\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[106]\tvalid_0's auc: 0.634442\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[107]\tvalid_0's auc: 0.634487\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[108]\tvalid_0's auc: 0.634578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[109]\tvalid_0's auc: 0.634676\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[110]\tvalid_0's auc: 0.63479\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[111]\tvalid_0's auc: 0.634846\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[112]\tvalid_0's auc: 0.634918\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[113]\tvalid_0's auc: 0.63501\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[114]\tvalid_0's auc: 0.634965\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[115]\tvalid_0's auc: 0.635029\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[116]\tvalid_0's auc: 0.635077\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[117]\tvalid_0's auc: 0.635075\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[118]\tvalid_0's auc: 0.6352\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[119]\tvalid_0's auc: 0.635215\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[120]\tvalid_0's auc: 0.635231\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[121]\tvalid_0's auc: 0.635276\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[122]\tvalid_0's auc: 0.635268\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[123]\tvalid_0's auc: 0.635221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 19\n",
      "[124]\tvalid_0's auc: 0.635178\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[125]\tvalid_0's auc: 0.635221\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[126]\tvalid_0's auc: 0.635288\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[127]\tvalid_0's auc: 0.635345\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[128]\tvalid_0's auc: 0.635348\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[129]\tvalid_0's auc: 0.635414\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[130]\tvalid_0's auc: 0.635418\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[131]\tvalid_0's auc: 0.635352\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[132]\tvalid_0's auc: 0.635402\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[133]\tvalid_0's auc: 0.635497\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[134]\tvalid_0's auc: 0.635545\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[135]\tvalid_0's auc: 0.63565\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[136]\tvalid_0's auc: 0.635622\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[137]\tvalid_0's auc: 0.635664\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[138]\tvalid_0's auc: 0.635781\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[139]\tvalid_0's auc: 0.635735\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[140]\tvalid_0's auc: 0.635719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[141]\tvalid_0's auc: 0.635815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[142]\tvalid_0's auc: 0.635799\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[143]\tvalid_0's auc: 0.63583\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[144]\tvalid_0's auc: 0.635898\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[145]\tvalid_0's auc: 0.635924\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[146]\tvalid_0's auc: 0.635885\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[147]\tvalid_0's auc: 0.635919\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[148]\tvalid_0's auc: 0.63598\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[149]\tvalid_0's auc: 0.636035\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[150]\tvalid_0's auc: 0.636087\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[151]\tvalid_0's auc: 0.636139\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[152]\tvalid_0's auc: 0.63617\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[153]\tvalid_0's auc: 0.636128\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[154]\tvalid_0's auc: 0.636096\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[155]\tvalid_0's auc: 0.636206\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[156]\tvalid_0's auc: 0.636259\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[157]\tvalid_0's auc: 0.636289\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[158]\tvalid_0's auc: 0.636283\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[159]\tvalid_0's auc: 0.636287\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 20\n",
      "[160]\tvalid_0's auc: 0.636293\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[161]\tvalid_0's auc: 0.636324\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[162]\tvalid_0's auc: 0.63633\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[163]\tvalid_0's auc: 0.636367\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[164]\tvalid_0's auc: 0.636438\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[165]\tvalid_0's auc: 0.636483\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[166]\tvalid_0's auc: 0.636577\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[167]\tvalid_0's auc: 0.636645\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[168]\tvalid_0's auc: 0.63659\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[169]\tvalid_0's auc: 0.636595\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[170]\tvalid_0's auc: 0.636672\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[171]\tvalid_0's auc: 0.636719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[172]\tvalid_0's auc: 0.636755\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[173]\tvalid_0's auc: 0.636833\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[174]\tvalid_0's auc: 0.636908\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[175]\tvalid_0's auc: 0.636929\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[176]\tvalid_0's auc: 0.636928\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[177]\tvalid_0's auc: 0.636962\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[178]\tvalid_0's auc: 0.636969\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[179]\tvalid_0's auc: 0.636995\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[180]\tvalid_0's auc: 0.637059\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[181]\tvalid_0's auc: 0.637089\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[182]\tvalid_0's auc: 0.637085\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[183]\tvalid_0's auc: 0.637121\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[184]\tvalid_0's auc: 0.637131\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[185]\tvalid_0's auc: 0.637133\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[186]\tvalid_0's auc: 0.637144\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[187]\tvalid_0's auc: 0.637189\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[188]\tvalid_0's auc: 0.637173\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[189]\tvalid_0's auc: 0.63719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[190]\tvalid_0's auc: 0.637205\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 20\n",
      "[191]\tvalid_0's auc: 0.637131\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[192]\tvalid_0's auc: 0.637159\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[193]\tvalid_0's auc: 0.637185\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[194]\tvalid_0's auc: 0.63719\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[195]\tvalid_0's auc: 0.637224\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[196]\tvalid_0's auc: 0.637219\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[197]\tvalid_0's auc: 0.637193\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[198]\tvalid_0's auc: 0.637297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[199]\tvalid_0's auc: 0.637329\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[200]\tvalid_0's auc: 0.6373\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[201]\tvalid_0's auc: 0.637257\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[202]\tvalid_0's auc: 0.637253\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[203]\tvalid_0's auc: 0.637261\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[204]\tvalid_0's auc: 0.637252\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[205]\tvalid_0's auc: 0.637273\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[206]\tvalid_0's auc: 0.637297\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[207]\tvalid_0's auc: 0.637345\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[208]\tvalid_0's auc: 0.637401\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[209]\tvalid_0's auc: 0.637456\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 19\n",
      "[210]\tvalid_0's auc: 0.637392\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[211]\tvalid_0's auc: 0.637373\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[212]\tvalid_0's auc: 0.63741\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[213]\tvalid_0's auc: 0.637459\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[214]\tvalid_0's auc: 0.637496\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[215]\tvalid_0's auc: 0.637539\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[216]\tvalid_0's auc: 0.637546\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[217]\tvalid_0's auc: 0.637535\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[218]\tvalid_0's auc: 0.637511\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[219]\tvalid_0's auc: 0.6375\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 20\n",
      "[220]\tvalid_0's auc: 0.637502\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[221]\tvalid_0's auc: 0.637493\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[222]\tvalid_0's auc: 0.637431\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[223]\tvalid_0's auc: 0.637413\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[224]\tvalid_0's auc: 0.637421\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[225]\tvalid_0's auc: 0.637368\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[226]\tvalid_0's auc: 0.637374\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[227]\tvalid_0's auc: 0.637374\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[228]\tvalid_0's auc: 0.637413\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[229]\tvalid_0's auc: 0.637429\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[230]\tvalid_0's auc: 0.637437\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[231]\tvalid_0's auc: 0.637488\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[232]\tvalid_0's auc: 0.637531\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 18\n",
      "[233]\tvalid_0's auc: 0.637529\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[234]\tvalid_0's auc: 0.637567\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[235]\tvalid_0's auc: 0.637599\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 11\n",
      "[236]\tvalid_0's auc: 0.637624\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[237]\tvalid_0's auc: 0.637659\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 16\n",
      "[238]\tvalid_0's auc: 0.637586\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[239]\tvalid_0's auc: 0.637656\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[240]\tvalid_0's auc: 0.637684\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[241]\tvalid_0's auc: 0.637682\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[242]\tvalid_0's auc: 0.637751\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[243]\tvalid_0's auc: 0.637722\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[244]\tvalid_0's auc: 0.637714\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[245]\tvalid_0's auc: 0.637647\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[246]\tvalid_0's auc: 0.637679\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[247]\tvalid_0's auc: 0.637679\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 13\n",
      "[248]\tvalid_0's auc: 0.637735\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[249]\tvalid_0's auc: 0.6377\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[250]\tvalid_0's auc: 0.637738\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[251]\tvalid_0's auc: 0.637708\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[252]\tvalid_0's auc: 0.637688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[253]\tvalid_0's auc: 0.637725\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 10\n",
      "[254]\tvalid_0's auc: 0.637697\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[255]\tvalid_0's auc: 0.637689\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[256]\tvalid_0's auc: 0.637714\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 21\n",
      "[257]\tvalid_0's auc: 0.637688\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[258]\tvalid_0's auc: 0.637732\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 12\n",
      "[259]\tvalid_0's auc: 0.637703\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 17\n",
      "[260]\tvalid_0's auc: 0.63775\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 15\n",
      "[261]\tvalid_0's auc: 0.637715\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 60 and max_depth = 14\n",
      "[262]\tvalid_0's auc: 0.637711\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's auc: 0.637751\n",
      "{'auc': 0.6377511613946426}\n",
      "/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/mounts/workspaceblobstore/azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/model_folder/driver_model.pkl\n",
      "<lightgbm.basic.Booster object at 0x7f83740b2828>\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 109\n",
      "\n",
      "\n",
      "[2021-01-24T17:24:11.227237] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.17198777198791504 seconds\n",
      "[2021-01-24T17:24:11.736142] Finished context manager injector.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      "===============================================================================================================\n",
      "[2021-01-24T17:24:15.763827] Entering job release\n",
      "[2021-01-24T17:24:16.688991] Starting job release\n",
      "[2021-01-24T17:24:16.689891] Logging experiment finalizing status in history service.\n",
      "[2021-01-24T17:24:16.690090] job release stage : upload_datastore starting...\n",
      "[2021-01-24T17:24:16.690365] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-01-24T17:24:16.690432] job release stage : execute_job_release starting...\n",
      "[2021-01-24T17:24:16.690734] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-01-24T17:24:16.690814] job release stage : copy_batchai_cached_logs completed...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 433\n",
      "[2021-01-24T17:24:16.704875] Entering context manager injector.\n",
      "[2021-01-24T17:24:16.938971] job release stage : upload_datastore completed...\n",
      "[2021-01-24T17:24:16.951384] job release stage : send_run_telemetry starting...\n",
      "[2021-01-24T17:24:17.147863] job release stage : execute_job_release completed...\n",
      "[2021-01-24T17:24:18.149116] job release stage : send_run_telemetry completed...\n",
      "[2021-01-24T17:24:18.149412] Job release is complete\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': '8608c8e0-c7ca-4451-b358-6b3cd38851f4', 'target': 'cpu-cluster1', 'status': 'Completed', 'startTimeUtc': '2021-01-24T17:15:42.66329Z', 'endTimeUtc': '2021-01-24T17:24:35.618569Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'abf0ed80-fa52-44ea-bd06-398759dc7497', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '23bd3cb7-de8c-44a6-bf59-e94917378231', 'azureml.nodeid': '74ff141f', 'azureml.pipelinerunid': 'ec8f41a2-5f6c-4b76-bf59-23985951e381', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '06785b22-0f99-4b39-af4c-1f44718a15e4'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'driversdataset', 'mechanism': 'Direct'}}, {'dataset': {'id': '06785b22-0f99-4b39-af4c-1f44718a15e4'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_drivers.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster1', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'driversdataset': {'dataLocation': {'dataset': {'id': '06785b22-0f99-4b39-af4c-1f44718a15e4', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'driversdataset', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'environment': {'name': 'drivers-pipeline-env', 'version': '4', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.19.0', 'azureml-dataprep[pandas]']}, 'scikit-learn', 'pandas', 'lightgbm'], 'name': 'azureml_3bb039051544a835c8510fbe091702bf'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=X%2FSacnQdyUrzOv6%2BMBfNP6hfhQ1k3KFCUCgehEeNEXk%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/55_azureml-execution-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt?sv=2019-02-02&sr=b&sig=bOTzXfhdrnzxrCECQwBf%2F1OMuZ2mfKLcXHF4Sa9eBk8%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'azureml-logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt?sv=2019-02-02&sr=b&sig=0E5fw%2FOScNhxiJfGROZeE6T%2Brso6OTUZXIyBfT1Quic%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=VpiY8AIeKLK995Fh1i8Pjkz7NdX%2BdYCA7Uibue%2FkfiQ%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'azureml-logs/75_job_post-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/75_job_post-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt?sv=2019-02-02&sr=b&sig=1U6lm8QeEmwiY4a2n%2FVPMVueHVNYVGV43HCf1JgQjMo%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'azureml-logs/process_info.json': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=pfuEb5OLnKpC4nplWUs4fjojeUE9VUdsDvrRd3pkvpQ%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'azureml-logs/process_status.json': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=a05Fb3EjtpUMq20MSThyVdO0%2Fa1nhSvN5yWmYT15kow%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/109_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=Tf3I87cgRSfkKqe3XZ%2Fix7JcrINtfRE4aX8XsOahWkw%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=QVe%2FSicC8kXTfFSUdeEJQHUhl%2FHacBKize6jtJEowCQ%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=B%2BWf9povrL8%2B51d2bCN6Luez69COG7D5csykV1Osp0Q%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=duzrNPB5fknpinyaREn%2FmxlQbxZrsGyjg%2FV58eUwvyw%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=5G4VZXfXsaL2ySOkwKWsmC2WRc42pNZ5DiIyDcZd0vQ%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=O1qtrf2QDx1kZliQ64Fri%2Bkg8ntEoabYBCMMg%2BY3Zgk%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=rFJPqj%2F23JxMoyTU48SB3xB3OXSeqQtHwW48fRiS1Go%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.8608c8e0-c7ca-4451-b358-6b3cd38851f4/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Gt0X%2Be3%2FfcfgifY9QFo%2BuuNmdmR%2Bt19DNqarEDUX2b0%3D&st=2021-01-24T17%3A14%3A19Z&se=2021-01-25T01%3A24%3A19Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: 39e81cf3-9b2a-4557-b7ed-db126976188a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/39e81cf3-9b2a-4557-b7ed-db126976188a?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      "========================================================================================================================\n",
      "2021-01-24T17:24:53Z Starting output-watcher...\n",
      "2021-01-24T17:24:53Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-01-24T17:24:54Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-01-24T17:24:54Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      "Digest: sha256:5725a4c975a182db05ccd3b876974ef0bf64345fe498d4c404ad85c8cf9f0f69\n",
      "Status: Image is up to date for mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest\n",
      "mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e:latest\n",
      "2021-01-24T17:24:55Z Check if container 39e81cf3-9b2a-4557-b7ed-db126976188a already exist exited with 0, \n",
      "\n",
      "e8a054b6a838870679c2cd82af4b9de63e6d399f750803b8c51d2dc332070a4e\n",
      "2021/01/24 17:24:56 Starting App Insight Logger for task:  containerSetup\n",
      "2021/01/24 17:24:56 Version: 3.0.01467.0023 Branch: .SourceBranch Commit: 8f9022f\n",
      "2021/01/24 17:24:56 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/01/24 17:24:56 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/01/24 17:24:56 sshd inside container not required for job, skipping setup.\n",
      "2021/01/24 17:24:56 All App Insights Logs was send successfully\n",
      "2021-01-24T17:24:56Z Starting docker container succeeded.\n",
      "2021-01-24T17:25:03Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/01/24 17:24:51 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/01/24 17:24:51 Version: 3.0.01467.0023 Branch: .SourceBranch Commit: 8f9022f\n",
      ">>>   2021/01/24 17:24:51 runtime.GOOS linux\n",
      ">>>   2021/01/24 17:24:51 Reading dyanamic configs\n",
      ">>>   2021/01/24 17:24:51 Container sas url: https://baiscriptsdm1prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=jERbQtYUS5wH4oi8gxo4Rfe9yxPy25mLk7UYJIRzAsA%3D\n",
      ">>>   2021/01/24 17:24:51 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: not a directory\n",
      ">>>   2021/01/24 17:24:51 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed true, isEnable true,\n",
      ">>>   2021/01/24 17:24:51 azsecpack isEnable:true,GetDisableVsatlsscan:true\n",
      ">>>   2021/01/24 17:24:51 start to install azsecpack..., MachineName is 8123289e505549148fc0913dc8378106000000 \n",
      ">>>   \n",
      ">>>   2021/01/24 17:24:51 \n",
      ">>>   2021/01/24 17:24:51 \n",
      ">>>   2021/01/24 17:24:51 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/01/24 17:24:51 DetonationChamber is not enabled on this subscription: c46a9435-c957-4e6c-a0f4-b9a597984773\n",
      ">>>   2021/01/24 17:24:51 GPU count found: 0\n",
      ">>>   2021/01/24 17:24:51 AMLComputeXDSEndpoint:  https://dm1-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/01/24 17:24:51 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/01/24 17:24:51 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config\n",
      ">>>   2021/01/24 17:24:51 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/01/24 17:24:51 Starting identity responder.\n",
      ">>>   2021/01/24 17:24:51 Starting identity responder.\n",
      ">>>   2021/01/24 17:24:51 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2021/01/24 17:24:51 Logfile used for identity responder: /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/IdentityResponderLog-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:24:51 Logfile used for identity responder: /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/IdentityResponderLog-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:24:51 Started Identity Responder for job.\n",
      ">>>   2021/01/24 17:24:51 Started Identity Responder for job.\n",
      ">>>   2021/01/24 17:24:51 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/wd\n",
      ">>>   2021/01/24 17:24:51 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/shared\n",
      ">>>   2021/01/24 17:24:51 Mounting job level file systems\n",
      ">>>   2021/01/24 17:24:51 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts\n",
      ">>>   2021/01/24 17:24:51 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/01/24 17:24:51 Datastore credentials file not found, skipping.\n",
      ">>>   2021/01/24 17:24:51 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.master.runtimesastokens\n",
      ">>>   2021/01/24 17:24:51 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/01/24 17:24:51 No NFS configured\n",
      ">>>   2021/01/24 17:24:51 No Azure File Shares configured\n",
      ">>>   2021/01/24 17:24:51 Mounting blob file systems\n",
      ">>>   2021/01/24 17:24:51 Blobfuse runtime version blobfuse 1.3.6\n",
      ">>>   2021/01/24 17:24:51 Mounting azureml-blobstore-0fb30f4c-f96f-4ccb-98e8-b741ce9e8f19 container from mlopsdev3695286978 account at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:24:51 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/01/24 17:24:51 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/01/24 17:24:51 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/01/24 17:24:51 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:24:51 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:24:51 Successfully mounted azureml-blobstore-0fb30f4c-f96f-4ccb-98e8-b741ce9e8f19 container from mlopsdev3695286978 account at /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore\n",
      ">>>   2021/01/24 17:24:51 No unmanaged file systems configured\n",
      ">>>   2021/01/24 17:24:51 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/01/24 17:24:51 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs\n",
      ">>>   2021/01/24 17:24:52 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/logs\n",
      ">>>   2021/01/24 17:24:53 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/outputs\n",
      ">>>   2021/01/24 17:24:53 Starting output-watcher...\n",
      ">>>   2021/01/24 17:24:53 Single file input dataset is enabled.\n",
      ">>>   2021/01/24 17:24:53 Start to pulling docker image: mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      ">>>   2021/01/24 17:24:53 Start pull docker image: mlopsdev82752047.azurecr.io\n",
      ">>>   2021/01/24 17:24:53 Container registry is ACR.\n",
      ">>>   2021/01/24 17:24:53 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/01/24 17:24:53 Getting ACR Credentials from EMS for environment drivers-pipeline-env:4\n",
      ">>>   2021/01/24 17:24:53 Requesting XDS for registry details.\n",
      ">>>   2021/01/24 17:24:53 Attempt 1 of http call to https://dm1-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourceGroups/mlops/workspaces/mlopsdev/clusters/cpu-cluster1/nodes/tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d?api-version=2018-02-01\n",
      ">>>   2021/01/24 17:24:54 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2021/01/24 17:24:54 Got container registry details from credentials service for registry address: mlopsdev82752047.azurecr.io.\n",
      ">>>   2021/01/24 17:24:54 Writing ACR Details to file...\n",
      ">>>   2021/01/24 17:24:54 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/01/24 17:24:54 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/01/24 17:24:54 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/01/24 17:24:54 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/01/24 17:24:54 EMS returned mlopsdev82752047.azurecr.io for environment drivers-pipeline-env\n",
      ">>>   2021/01/24 17:24:54 start login to the docker registry\n",
      ">>>   2021/01/24 17:24:54 Successfully logged into the docker registry.\n",
      ">>>   2021/01/24 17:24:54 Start run pull docker image command\n",
      ">>>   2021/01/24 17:24:54 Pull docker image succeeded.\n",
      ">>>   2021/01/24 17:24:54 Pull docker image time: 945.150095ms\n",
      ">>>   \n",
      ">>>   2021/01/24 17:24:55 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/01/24 17:24:55 Setting the memory limit for docker container to be 112457 MB\n",
      ">>>   2021/01/24 17:24:55 The env variable file size is 36489 bytes\n",
      ">>>   2021/01/24 17:24:55 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,39e81cf3-9b2a-4557-b7ed-db126976188a,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/certs:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,112457m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd,-v,/opt/azureml:/opt/azureml:ro,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.batchai.envlist\n",
      ">>>   2021/01/24 17:24:55 the binding /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a \n",
      ">>>   2021/01/24 17:24:55 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,39e81cf3-9b2a-4557-b7ed-db126976188a,-m,112457m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.batchai.envlist,-v,/opt/azureml:/opt/azureml:ro,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd,-v,/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/certs:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/certs\n",
      ">>>   2021/01/24 17:24:55 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/01/24 17:24:55 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 39e81cf3-9b2a-4557-b7ed-db126976188a -m 112457m -w /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/config/.batchai.envlist -v /opt/azureml:/opt/azureml:ro -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a:/mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a -v /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd -v /mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/certs:/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/certs --shm-size 2g -d -it --privileged --net=host mlopsdev82752047.azurecr.io/azureml/azureml_9d6872fa3e0318d28106f2e21ec8c44e\n",
      ">>>   2021/01/24 17:24:55 Check if container 39e81cf3-9b2a-4557-b7ed-db126976188a already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/01/24 17:24:55 Check if container 39e81cf3-9b2a-4557-b7ed-db126976188a already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/01/24 17:24:56 Attempt 1 of http call to https://centralus.experiments.azureml.net/history/v1.0/private/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourceGroups/mlops/providers/Microsoft.MachineLearningServices/workspaces/mlopsdev/runs/39e81cf3-9b2a-4557-b7ed-db126976188a/spans\n",
      ">>>   2021/01/24 17:24:56 Container ssh is not required for job type.\n",
      ">>>   2021/01/24 17:24:56 Starting docker container succeeded.\n",
      ">>>   2021/01/24 17:24:56 Starting docker container succeeded.\n",
      ">>>   2021/01/24 17:24:56 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs\n",
      ">>>   2021/01/24 17:24:56 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"abf0ed80-fa52-44ea-bd06-398759dc7497\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/01/24 17:24:56 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:24:56 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/azureml_compute_logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      ">>>   2021/01/24 17:24:56 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a;/azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"abf0ed80-fa52-44ea-bd06-398759dc7497\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/01/24 17:24:57 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/01/24 17:24:57 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t 39e81cf3-9b2a-4557-b7ed-db126976188a bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/d08c0051-96ea-43eb-9a2b-f35cead275cf/job-1/39e81cf3-9b2a-4557-b_0275a25e-8159-47a9-9f69-3de16d8f316d/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a;/azureml-envs/azureml_3bb039051544a835c8510fbe091702bf/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlopsdev/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a/mounts/workspaceblobstore/azureml/39e81cf3-9b2a-4557-b7ed-db126976188a-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"abf0ed80-fa52-44ea-bd06-398759dc7497\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:57.457307] Entering job preparation.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:58.680875] Starting job preparation.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:58.680930] Extracting the control code.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:58.713205] fetching and extracting the control code on master node.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:58.713251] Starting extract_project.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:58.713298] Starting to extract zip file.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:59.446285] Finished extracting zip file.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:59.614406] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:59.614476] Start fetching snapshots.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:59.614519] Start fetching snapshot.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:24:59.614536] Retrieving project from snapshot: abf0ed80-fa52-44ea-bd06-398759dc7497\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 55\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.633518] Finished fetching snapshot.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.633572] Finished fetching snapshots.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.633616] Finished extract_project.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.644984] Finished fetching and extracting the control code.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.648993] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.650815] Start run_history_prep.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:02.693953] Entering context manager injector.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: Acquired lockfile /tmp/39e81cf3-9b2a-4557-b7ed-db126976188a-datastore.lock to downloading input data references\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:03.252402] downloadDataStore completed\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:03.256276] Job preparation is complete.\n",
      ">>>   2021/01/24 17:25:03 runSpecialJobTask: preparation: [2021-01-24T17:25:03.256321] Running Context Managers in Sidecar complete.\n",
      ">>>   2021/01/24 17:25:03 All App Insights Logs was send successfully\n",
      ">>>   2021/01/24 17:25:03 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2021-01-24T17:25:03Z 127.0.0.1 slots=16 max-slots=16\n",
      "2021-01-24T17:25:03Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt\n",
      "===============================================================================================================\n",
      "[2021-01-24T17:25:12.791150] Entering job release\n",
      "[2021-01-24T17:25:13.753638] Starting job release\n",
      "[2021-01-24T17:25:13.758429] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 163\n",
      "[2021-01-24T17:25:13.758937] job release stage : upload_datastore starting...\n",
      "[2021-01-24T17:25:13.759770] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-01-24T17:25:13.763400] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-01-24T17:25:13.770208] job release stage : execute_job_release starting...\n",
      "[2021-01-24T17:25:13.770365] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-01-24T17:25:13.771638] Entering context manager injector.\n",
      "[2021-01-24T17:25:13.967044] job release stage : upload_datastore completed...\n",
      "[2021-01-24T17:25:14.014819] job release stage : send_run_telemetry starting...\n",
      "[2021-01-24T17:25:14.174543] job release stage : execute_job_release completed...\n",
      "[2021-01-24T17:25:14.869688] job release stage : send_run_telemetry completed...\n",
      "[2021-01-24T17:25:14.870019] Job release is complete\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': '39e81cf3-9b2a-4557-b7ed-db126976188a', 'target': 'cpu-cluster1', 'status': 'Completed', 'startTimeUtc': '2021-01-24T17:24:54.516644Z', 'endTimeUtc': '2021-01-24T17:25:25.456891Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'abf0ed80-fa52-44ea-bd06-398759dc7497', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '7963a442-8156-44f6-bacc-4b6e0b644928', 'azureml.nodeid': 'a76527d9', 'azureml.pipelinerunid': 'ec8f41a2-5f6c-4b76-bf59-23985951e381', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_model.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster1', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/8608c8e0-c7ca-4451-b358-6b3cd38851f4/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'environment': {'name': 'drivers-pipeline-env', 'version': '4', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.19.0', 'azureml-dataprep[pandas]']}, 'scikit-learn', 'pandas', 'lightgbm'], 'name': 'azureml_3bb039051544a835c8510fbe091702bf'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/azureml-logs/55_azureml-execution-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt?sv=2019-02-02&sr=b&sig=FysZlmeCehfkBiTOiPOBQqFASBA7iJAxF%2B0fxwy53No%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'azureml-logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/azureml-logs/65_job_prep-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt?sv=2019-02-02&sr=b&sig=o7I20GAFuulpX2sBdjL%2BWlc%2FHS9r4LENEl3ouHQIE10%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=fx2oLhHsxVfZxgqLlMxXE7kgCuCuUMZuYmabB9cTE4A%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'azureml-logs/75_job_post-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/azureml-logs/75_job_post-tvmps_ca19ec4be3a1478b028cc17fd7c59dfd56bbe8d64b2222728a6a01ac727253a5_d.txt?sv=2019-02-02&sr=b&sig=brpLl4Y4aW1RmMIS8z9XtZERhgiZ2pAdsyv1u36bB1o%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'logs/azureml/109_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/logs/azureml/109_azureml.log?sv=2019-02-02&sr=b&sig=my1wDHlaeno1%2FM7KQJT9QPFLeCS8HY8ewZqIGn0WL%2Fs%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=AGp0MXqCk3KACvdNX3EtNYkFbrqdBqkc8bTvnVJjKVo%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=mLXFjcT3C05zq4aEtHFg%2Bqyq83kLqZDQWIxuuNC3%2F00%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=BJ7pP3KuPDgB0zh3tnDMbckvoerYYfzG9s1xV1phcKY%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=lYyx32%2FdbcWCJLCCg3jYSCV8jes0eePF7wY2ofe2fxY%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.39e81cf3-9b2a-4557-b7ed-db126976188a/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=v6doPMyVoovRUJ0TYTH5ZAzUqyBt3MfSh18jvSjvvvM%3D&st=2021-01-24T17%3A15%3A16Z&se=2021-01-25T01%3A25%3A16Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'ec8f41a2-5f6c-4b76-bf59-23985951e381', 'status': 'Completed', 'startTimeUtc': '2021-01-24T17:06:54.635608Z', 'endTimeUtc': '2021-01-24T17:25:40.471615Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=UyMuP8M6mWEmakCQr8BeqMIgQ43yRPgYl1kBeRW%2F6so%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=n0EiayrsviDSH8gSR5W%2F6%2F3LfxJsSGoxSHv8PoWuS6g%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=K0aDrhW9f981DfZYO%2BcF%2BRgOVDtVVC86vS%2Bj%2BNreOOg%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline, which contains Step 1 & 2\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'driver-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_model version: 3\n",
      "\n",
      "\n",
      "driver_model.pkl version: 9\n",
      "\n",
      "\n",
      "driver_model.pkl version: 8\n",
      "\t Accuracy : {'auc': 0.6377511613946426, 'f1score': 1.0}\n",
      "\t learningrate : 0.02\n",
      "\t f1score : 1.0\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "NYCGreenTaxiModel version: 1\n",
      "\n",
      "\n",
      "driver_model version: 2\n",
      "\n",
      "\n",
      "driver_model.pkl version: 7\n",
      "\t Accuracy : {'auc': 0.6377511613946426, 'f1score': 1.0}\n",
      "\t learningrate : 0.02\n",
      "\t f1score : 1.0\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "gpt-2 version: 1\n",
      "\t title : GPT-2 model card\n",
      "\t datasheet_description : \n",
      "Last updated: November 2019\n",
      "\n",
      "Inspired by [Model Cards for Model Reporting (Mitchell et al.)](https://arxiv.org/abs/1810.03993), weâ€™re providing some accompanying information about the GPT-2 family of models we're releasing.\n",
      "\n",
      "\n",
      "\t details : This model was developed by researchers at OpenAI to help us understand how the capabilities of language model capabilities scale as a function of the size of the models (by parameter count) combined with very large internet-scale datasets (WebText).\n",
      "\t date : February 2019, trained on data that cuts off at the end of 2017.\n",
      "\t type : Language model\n",
      "\t version : 1.5 billion parameters: the fourth and largest GPT-2 version. We have also released 124 million, 355 million, and 774 million parameter models.\n",
      "\t help : https://forms.gle/A7WBSbTY2EkKdroPA\n",
      "\t usecase_primary : \n",
      "The primary intended users of these models are *AI researchers and practitioners*.\n",
      "\n",
      "We primarily imagine these language models will be used by researchers to better understand the behaviors, capabilities, biases, and                                 constraints of large-scale generative language models.\n",
      "\n",
      "\t usecase_secondary : \n",
      "Here are some secondary use cases we believe are likely:\n",
      "\n",
      "- **Writing assistance**: Grammar assistance, autocompletion (for normal prose or code)\n",
      "- **Creative writing and art**: exploring the generation of creative, fictional texts; aiding creation of poetry and other literary art.\n",
      "- **Entertainment**: Creation of games, chat bots, and amusing generations.\n",
      "\n",
      "\t usecase_outofscope : \n",
      "Because large-scale language models like GPT-2 do not distinguish fact from fiction, we donâ€™t support use-cases that require the generated text to be true.\n",
      "\n",
      "Additionally, language models like GPT-2 reflect the biases inherent to the systems they were trained on, so we do not recommend that they be deployed into systems that interact with humans unless the deployers first carry out a study of biases relevant to the intended use-case. We found no statistically significant difference in gender, race, and religious bias probes between 774M and 1.5B, implying all versions of GPT-2 should be approached with similar levels of caution around use cases that are sensitive to biases around human attributes.\n",
      "\n",
      "\t dataset_description : \n",
      "This model was trained on (and evaluated against) WebText, a dataset consisting of the text contents of 45 million links posted by users of the â€˜Redditâ€™ social network. WebText is made of data derived from outbound links from Reddit and does not consist of data taken directly from Reddit itself. Before generating the dataset we used a blocklist to ensure we didnâ€™t sample from a variety of subreddits which contain sexually explicit or otherwise offensive content.\n",
      "\n",
      "To get a sense of the data that went into GPT-2, weâ€™ve [published a list](domains.txt) of the top 1,000 domains present in WebText and their frequency.  The top 15 domains by volume in WebText are: Google, Archive, Blogspot, GitHub, NYTimes, Wordpress, Washington Post, Wikia, BBC, The Guardian, eBay, Pastebin, CNN, Yahoo!, and the Huffington Post.\n",
      "\n",
      "\t motivation : The motivation behind WebText was to create an Internet-scale, heterogeneous dataset that we could use to test large-scale language models against. WebText was (and is) intended to be primarily for research purposes rather than production purposes.\n",
      "\t caveats : \n",
      "Because GPT-2 is an internet-scale language model, itâ€™s currently difficult to know what disciplined testing procedures can be applied to it to fully understand its capabilities and how the data it is trained on influences its vast range of outputs. We recommend researchers investigate these aspects of the model and share their results.\n",
      "\n",
      "Additionally, as indicated in our discussion of issues relating to potential misuse of the model, it remains unclear what the long-term dynamics are of detecting outputs from these models. We conducted [in-house automated ML-based detection research](https://github.com/openai/gpt-2-output-dataset/tree/master/detector) using simple classifiers, zero shot, and fine-tuning methods. Our fine-tuned detector model reached accuracy levels of approximately 95%. However, no one detection method is a panacea; automated ML-based detection, human detection, human-machine teaming, and metadata-based detection are all methods that can be combined for more confident classification. Developing better approaches to detection today will give us greater intuitions when thinking about future models and could help us understand ahead of time if detection methods will eventually become ineffective.\n",
      "\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 11\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : ef18ea38-d545-422e-95dc-81e869c78814\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t f1score : 1.0\n",
      "\t BuildId : 107\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=107\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 10\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 5ff90326-b105-4353-ab02-60cd771e99ea\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t f1score : 1.0\n",
      "\t BuildId : 105\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=105\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 9\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : cc4f2b8b-ca37-4631-92c4-57dd99e34d10\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t f1score : 1.0\n",
      "\t BuildId : 103\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=103\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 8\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : bf9aaf6b-0703-41d6-a16a-aad50d4d910a\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t f1score : 1.0\n",
      "\t BuildId : 100\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=100\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 7\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 76245268-7add-41e6-97ee-40dcf3829be3\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 88\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=88\n",
      "\n",
      "\n",
      "driver_model.pkl version: 6\n",
      "\t Accuracy : {'auc': 0.6377511613946426, 'f1score': 1.0}\n",
      "\t learningrate : 0.02\n",
      "\t f1score : 1.0\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "driver_model.pkl version: 5\n",
      "\t Accuracy : {'auc': 0.6377511613946426, 'f1score': 1.0}\n",
      "\t learningrate : 0.02\n",
      "\t f1score : 1.0\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 6\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 6277c46c-f18f-45cc-86bb-e31abbf10664\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 86\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=86\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 5\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 251625e2-490b-459b-94c8-53dc400a99a2\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 78\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=78\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 4\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 6ee98717-2465-4dc4-b2c6-b847ab8b2301\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 75\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=75\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 3\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 6c249903-e8f2-484c-ac69-3c1fc62089b6\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 67\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=67\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 2\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 0333337b-390b-4263-9084-a7e3f7fcc962\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 64\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=64\n",
      "\n",
      "\n",
      "drivers_model.pkl version: 1\n",
      "\t area : drivers_lightgbm\n",
      "\t run_id : 2dc78125-74de-4966-b96a-558aaf74ca1c\n",
      "\t experiment_name : driver-training-ops\n",
      "\t auc : 0.6377511613946426\n",
      "\t BuildId : 63\n",
      "\t BuildUri : https://babalgit.visualstudio.com/datascienceops082020/_build/results?buildId=63\n",
      "\n",
      "\n",
      "driver_model version: 1\n",
      "\n",
      "\n",
      "driver_model.pkl version: 4\n",
      "\t Accuracy : {'auc': 0.6377511613946426}\n",
      "\t learningrate : 0.02\n",
      "\n",
      "\n",
      "driver_model.pkl version: 3\n",
      "\t Accuracy : {'auc': 0.6387827870370796}\n",
      "\t learningrate : 0.01\n",
      "\n",
      "\n",
      "driver_model.pkl version: 2\n",
      "\t Accuracy : {'auc': 0.6387827870370796}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 1\n",
      "\t Accuracy : {'auc': 0.6377511613946426}\n",
      "\n",
      "\n",
      "census_grid_model_69 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_68 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_67 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_66 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_65 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_64 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_63 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_62 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_61 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_60 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_59 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_58 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_57 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_56 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_55 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_54 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_53 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_52 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_51 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_50 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_49 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_48 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_47 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_46 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_45 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_44 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_43 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_42 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_41 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_40 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_39 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_38 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_37 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_36 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_35 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_34 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_33 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_32 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_31 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_30 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_29 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_28 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_27 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_26 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_25 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_24 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_23 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_22 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_21 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_20 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_19 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_18 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_17 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_16 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_15 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_14 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_13 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_12 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_11 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_10 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_9 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_8 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_7 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_6 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_5 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_4 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_3 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_2 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_1 version: 1\n",
      "\n",
      "\n",
      "census_grid_model_0 version: 1\n",
      "\n",
      "\n",
      "census_unmitigated version: 1\n",
      "\n",
      "\n",
      "model_explain_model_on_amlcomp version: 2\n",
      "\n",
      "\n",
      "model_explain_model_on_amlcomp version: 1\n",
      "\n",
      "\n",
      "sklearn_diabetes version: 2\n",
      "\t Accuracy: : 0.8290094339622641\n",
      "\n",
      "\n",
      "sklearn_diabetes version: 1\n",
      "\n",
      "\n",
      "touring-model version: 6\n",
      "\n",
      "\n",
      "touring-model version: 5\n",
      "\n",
      "\n",
      "touring-model version: 4\n",
      "\n",
      "\n",
      "sklearn_touring version: 3\n",
      "\n",
      "\n",
      "sklearn_touring version: 2\n",
      "\n",
      "\n",
      "sklearn_touring version: 1\n",
      "\n",
      "\n",
      "sklearn_mnist version: 2\n",
      "\n",
      "\n",
      "sklearn_mnist version: 1\n",
      "\n",
      "\n",
      "mnist version: 1\n",
      "\t pretrained : mnist\n",
      "\n",
      "\n",
      "chd-predictor version: 4\n",
      "\t type : classification\n",
      "\t run_id : 25f0a9f3-2a72-4903-993e-de97f72626d4\n",
      "\t build_number : 20200430.2\n",
      "\n",
      "\n",
      "candy version: 1\n",
      "\t type : candy\n",
      "\t scenario : Style transfer using batch inference\n",
      "\n",
      "\n",
      "mosaic version: 1\n",
      "\t type : mosaic\n",
      "\t scenario : Style transfer using batch inference\n",
      "\n",
      "\n",
      "chd-predictor version: 3\n",
      "\t type : classification\n",
      "\t run_id : ea206b08-1f46-4264-a256-4bc1d62baf11\n",
      "\t build_number : 20200307.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the model name, version, tag, and properties\n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://centralus.api.azureml.ms/pipelines/v1.0/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourceGroups/mlops/providers/Microsoft.MachineLearningServices/workspaces/mlopsdev/PipelineRuns/PipelineSubmit/37ccd06c-3f50-400b-a434-699869c6f352\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = pipeline.publish(name=\"drivers_Training_Pipeline\",\n",
    "                                      description=\"Trains drivers model\",\n",
    "                                      version=\"1.0\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "experiment_name = 'Run-drivers-pipeline'\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173b155747d145fa841029ff117e7ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Run-drivers-pipeline/runs/f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\", \"run_id\": \"f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9\", \"run_properties\": {\"run_id\": \"f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9\", \"created_utc\": \"2021-01-24T17:48:02.266168Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"Unavailable\", \"runType\": \"HTTP\", \"azureml.parameters\": \"{}\", \"azureml.pipelineid\": \"37ccd06c-3f50-400b-a434-699869c6f352\"}, \"tags\": {\"azureml.pipelineid\": \"37ccd06c-3f50-400b-a434-699869c6f352\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-01-24T17:56:21.087891Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=DePEFgZnbpST5pGU15%2FkDKoqmInEOtQA79kWn6FcFRY%3D&st=2021-01-24T17%3A39%3A47Z&se=2021-01-25T01%3A49%3A47Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=qMVf2Rjqznf3GFUV6KFqqkqCo37IsBaecabe3AOT6ps%3D&st=2021-01-24T17%3A39%3A47Z&se=2021-01-25T01%3A49%3A47Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.f73c7d37-8b24-4f8f-aa1d-b0e136b6abe9/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=UWsU9KterEB%2BzYW%2FEDTVx5R5jZWfkS4fQbMBK7SDcFQ%3D&st=2021-01-24T17%3A39%3A47Z&se=2021-01-25T01%3A49%3A47Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:08:18\"}, \"child_runs\": [{\"run_id\": \"f2cb8c11-044b-4dc4-9768-7c14244c0d40\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:52:28.050224Z\", \"created_time\": \"2021-01-24T17:48:28.545139Z\", \"end_time\": \"2021-01-24T17:55:18.939985Z\", \"duration\": \"0:06:50\", \"run_number\": 10, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:48:28.545139Z\", \"is_reused\": \"\"}, {\"run_id\": \"1b73d5bc-c2cc-4de9-b6ba-97894b0a34e0\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:55:46.544565Z\", \"created_time\": \"2021-01-24T17:55:24.449175Z\", \"end_time\": \"2021-01-24T17:56:15.774794Z\", \"duration\": \"0:00:51\", \"run_number\": 11, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:55:24.449175Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-24 17:48:27Z] Submitting 1 runs, first five are: 74ff141f:f2cb8c11-044b-4dc4-9768-7c14244c0d40\\n[2021-01-24 17:55:24Z] Completing processing run id f2cb8c11-044b-4dc4-9768-7c14244c0d40.\\n[2021-01-24 17:55:24Z] Submitting 1 runs, first five are: a76527d9:1b73d5bc-c2cc-4de9-b6ba-97894b0a34e0\\n[2021-01-24 17:56:20Z] Completing processing run id 1b73d5bc-c2cc-4de9-b6ba-97894b0a34e0.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"ebe2e643\": {\"node_id\": \"ebe2e643\", \"name\": \"driversdataset\"}}, \"module_nodes\": {\"74ff141f\": {\"node_id\": \"74ff141f\", \"name\": \"Train Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"f2cb8c11-044b-4dc4-9768-7c14244c0d40\"}, \"a76527d9\": {\"node_id\": \"a76527d9\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"1b73d5bc-c2cc-4de9-b6ba-97894b0a34e0\"}}, \"edges\": [{\"source_node_id\": \"ebe2e643\", \"source_node_name\": \"driversdataset\", \"source_name\": \"data\", \"target_name\": \"driversdataset\", \"dst_node_id\": \"74ff141f\", \"dst_node_name\": \"Train Model\"}, {\"source_node_id\": \"74ff141f\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"a76527d9\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"f2cb8c11-044b-4dc4-9768-7c14244c0d40\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:52:28.050224Z\", \"created_time\": \"2021-01-24T17:48:28.545139Z\", \"end_time\": \"2021-01-24T17:55:18.939985Z\", \"duration\": \"0:06:50\", \"run_number\": 10, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:48:28.545139Z\", \"is_reused\": \"\"}, {\"run_id\": \"1b73d5bc-c2cc-4de9-b6ba-97894b0a34e0\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-01-24T17:55:46.544565Z\", \"created_time\": \"2021-01-24T17:55:24.449175Z\", \"end_time\": \"2021-01-24T17:56:15.774794Z\", \"duration\": \"0:00:51\", \"run_number\": 11, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-24T17:55:24.449175Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: ec8f41a2-5f6c-4b76-bf59-23985951e381\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/ec8f41a2-5f6c-4b76-bf59-23985951e381?wsid=/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourcegroups/mlops/workspaces/mlopsdev\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'ec8f41a2-5f6c-4b76-bf59-23985951e381', 'status': 'Completed', 'startTimeUtc': '2021-01-24T17:06:54.635608Z', 'endTimeUtc': '2021-01-24T17:25:40.471615Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=UyMuP8M6mWEmakCQr8BeqMIgQ43yRPgYl1kBeRW%2F6so%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=n0EiayrsviDSH8gSR5W%2F6%2F3LfxJsSGoxSHv8PoWuS6g%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlopsdev3695286978.blob.core.windows.net/azureml/ExperimentRun/dcid.ec8f41a2-5f6c-4b76-bf59-23985951e381/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=K0aDrhW9f981DfZYO%2BcF%2BRgOVDtVVC86vS%2Bj%2BNreOOg%3D&st=2021-01-24T16%3A57%3A16Z&se=2021-01-25T01%3A07%3A16Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#model_path = Model.get_model_path(model_name=\"driver_model.pkl\")\n",
    "model_path= \"./driver-training/driver_model.pkl\"\n",
    "LGBM_MODEL = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROW = '{\"data\":[[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],[4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "\n",
    "data = json.loads(TEST_ROW)[\"data\"]\n",
    "data = numpy.array(data)\n",
    "result = LGBM_MODEL.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02731105, 0.02612313])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
